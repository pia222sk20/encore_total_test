# 데이터 분석, 머신러닝, 딥러닝 종합 실습 문제 완성본

## 목차
- [Section 1: 데이터 분석 기초](#section-1-데이터-분석-기초)
- [Section 2: 데이터 전처리](#section-2-데이터-전처리)
- [Section 3: 데이터 시각화](#section-3-데이터-시각화)
- [Section 4: 머신러닝 알고리즘](#section-4-머신러닝-알고리즘)
- [Section 5: 딥러닝 및 NLP](#section-5-딥러닝-및-nlp)
- [Section 6: 모델 평가](#section-6-모델-평가)

---

## Section 1: 데이터 분석 기초

### 문제 1.1: NumPy를 활용한 벡터 및 행렬 연산

**지시사항:**
1. 두 벡터의 내적(dot product) 계산
2. 행렬 곱셈 구현
3. 벡터의 노름(norm) 계산
4. 조건부 인덱싱을 통한 데이터 필터링

**필요 라이브러리:**
```bash
pip install numpy matplotlib
```

**실행파일:** `problem_1_1_numpy_operations.py`

**소스코드:**
```python
"""
문제 1.1: NumPy를 활용한 벡터 및 행렬 연산

요구사항:
1. 두 벡터의 내적(dot product) 계산
2. 행렬 곱셈 구현
3. 벡터의 노름(norm) 계산
4. 조건부 인덱싱을 통한 데이터 필터링
"""

import numpy as np
import matplotlib.pyplot as plt

def main():
    print("=== 문제 1.1: NumPy를 활용한 벡터 및 행렬 연산 ===")
    
    # 1. 벡터 생성 및 내적 계산
    print("\n=== 1. 벡터 내적 계산 ===")
    vector_a = np.array([1, 2, 3, 4])
    vector_b = np.array([5, 6, 7, 8])
    
    # 내적 계산 (두 가지 방법)
    dot_product_1 = np.dot(vector_a, vector_b)
    dot_product_2 = vector_a @ vector_b
    
    print(f"벡터 A: {vector_a}")
    print(f"벡터 B: {vector_b}")
    print(f"내적 (np.dot): {dot_product_1}")
    print(f"내적 (@연산자): {dot_product_2}")
    
    # 수동 계산으로 검증
    manual_dot = sum(vector_a[i] * vector_b[i] for i in range(len(vector_a)))
    print(f"수동 계산 검증: {manual_dot}")
    
    # 2. 행렬 곱셈
    print("\n=== 2. 행렬 곱셈 ===")
    matrix_A = np.array([[1, 2, 3],
                        [4, 5, 6]])
    matrix_B = np.array([[7, 8],
                        [9, 10],
                        [11, 12]])
    
    # 행렬 곱셈
    matrix_product = np.matmul(matrix_A, matrix_B)
    matrix_product_2 = matrix_A @ matrix_B
    
    print(f"행렬 A (2x3):\n{matrix_A}")
    print(f"행렬 B (3x2):\n{matrix_B}")
    print(f"행렬 곱셈 결과 (2x2):\n{matrix_product}")
    
    # 3. 벡터의 노름 계산
    print("\n=== 3. 벡터 노름 계산 ===")
    vector_c = np.array([3, 4, 5])
    
    # 다양한 노름 계산
    l1_norm = np.linalg.norm(vector_c, ord=1)  # L1 노름
    l2_norm = np.linalg.norm(vector_c, ord=2)  # L2 노름 (유클리드 거리)
    inf_norm = np.linalg.norm(vector_c, ord=np.inf)  # 무한대 노름
    
    print(f"벡터 C: {vector_c}")
    print(f"L1 노름 (맨하탄 거리): {l1_norm}")
    print(f"L2 노름 (유클리드 거리): {l2_norm}")
    print(f"무한대 노름: {inf_norm}")
    
    # 수동 계산으로 L2 노름 검증
    manual_l2 = np.sqrt(sum(x**2 for x in vector_c))
    print(f"L2 노름 수동 계산: {manual_l2}")
    
    # 4. 조건부 인덱싱
    print("\n=== 4. 조건부 인덱싱 ===")
    data = np.array([1, 5, 3, 8, 2, 9, 4, 7, 6])
    
    print(f"원본 데이터: {data}")
    
    # 5보다 큰 값들 찾기
    greater_than_5 = data[data > 5]
    print(f"5보다 큰 값들: {greater_than_5}")
    
    # 짝수 값들 찾기
    even_values = data[data % 2 == 0]
    print(f"짝수 값들: {even_values}")
    
    # 범위 조건 (3 이상 7 이하)
    range_values = data[(data >= 3) & (data <= 7)]
    print(f"3 이상 7 이하 값들: {range_values}")
    
    # 조건에 따른 값 변경
    modified_data = data.copy()
    modified_data[modified_data > 5] = 100
    print(f"5보다 큰 값을 100으로 변경: {modified_data}")
    
    # 5. 통계 연산
    print("\n=== 5. 통계 연산 ===")
    random_data = np.random.rand(10) * 100
    random_data = random_data.astype(int)
    
    print(f"랜덤 데이터: {random_data}")
    print(f"평균: {np.mean(random_data):.2f}")
    print(f"중앙값: {np.median(random_data):.2f}")
    print(f"표준편차: {np.std(random_data):.2f}")
    print(f"최솟값: {np.min(random_data)}")
    print(f"최댓값: {np.max(random_data)}")
    print(f"합계: {np.sum(random_data)}")
    
    # 6. 시각화
    print("\n=== 6. 결과 시각화 ===")
    plt.figure(figsize=(12, 8))
    
    # 서브플롯 1: 벡터 시각화
    plt.subplot(2, 2, 1)
    x = np.arange(len(vector_a))
    plt.bar(x - 0.2, vector_a, 0.4, label='Vector A', alpha=0.7)
    plt.bar(x + 0.2, vector_b, 0.4, label='Vector B', alpha=0.7)
    plt.title('Vector Comparison')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    # 서브플롯 2: 행렬 히트맵
    plt.subplot(2, 2, 2)
    plt.imshow(matrix_product, cmap='viridis', aspect='auto')
    plt.colorbar()
    plt.title('Matrix Product Heatmap')
    
    # 서브플롯 3: 노름 비교
    plt.subplot(2, 2, 3)
    norms = [l1_norm, l2_norm, inf_norm]
    norm_names = ['L1', 'L2', 'L∞']
    plt.bar(norm_names, norms, color=['red', 'green', 'blue'], alpha=0.7)
    plt.title('Vector Norms Comparison')
    plt.ylabel('Norm Value')
    plt.grid(True, alpha=0.3)
    
    # 서브플롯 4: 조건부 필터링 결과
    plt.subplot(2, 2, 4)
    plt.scatter(range(len(data)), data, c='blue', label='Original', alpha=0.7)
    greater_5_indices = np.where(data > 5)[0]
    plt.scatter(greater_5_indices, data[greater_5_indices], c='red', label='> 5', s=100)
    plt.title('Conditional Filtering')
    plt.xlabel('Index')
    plt.ylabel('Value')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.show()

if __name__ == "__main__":
    main()
```

---

### 문제 1.2: NumPy 브로드캐스팅 이해 및 활용

**지시사항:**
1. 서로 다른 차원의 배열 간 연산
2. 브로드캐스팅 규칙 학습
3. 실제 데이터 처리 예제
4. 성능 비교 분석

**필요 라이브러리:**
```bash
pip install numpy matplotlib time
```

**실행파일:** `problem_1_2_numpy_broadcasting.py`

**소스코드:**
```python
"""
문제 1.2: NumPy 브로드캐스팅 이해 및 활용

요구사항:
1. 서로 다른 차원의 배열 간 연산
2. 브로드캐스팅 규칙 학습
3. 실제 데이터 처리 예제
4. 성능 비교 분석
"""

import numpy as np
import matplotlib.pyplot as plt
import time

def demonstrate_broadcasting_rules():
    """브로드캐스팅 규칙 시연"""
    print("=== 브로드캐스팅 규칙 시연 ===")
    
    # 규칙 1: 스칼라와 배열
    print("\n1. 스칼라와 배열")
    arr1 = np.array([1, 2, 3, 4])
    scalar = 10
    result1 = arr1 + scalar
    print(f"배열: {arr1}")
    print(f"스칼라: {scalar}")
    print(f"결과: {result1}")
    
    # 규칙 2: 1D 배열과 2D 배열
    print("\n2. 1D 배열과 2D 배열")
    arr2d = np.array([[1, 2, 3],
                      [4, 5, 6],
                      [7, 8, 9]])
    arr1d = np.array([10, 20, 30])
    result2 = arr2d + arr1d
    print(f"2D 배열:\n{arr2d}")
    print(f"1D 배열: {arr1d}")
    print(f"결과:\n{result2}")
    
    # 규칙 3: 서로 다른 차원의 배열
    print("\n3. 서로 다른 차원의 배열")
    arr_3x1 = np.array([[1], [2], [3]])
    arr_1x4 = np.array([10, 20, 30, 40])
    result3 = arr_3x1 + arr_1x4
    print(f"3x1 배열:\n{arr_3x1}")
    print(f"1x4 배열: {arr_1x4}")
    print(f"결과 (3x4):\n{result3}")
    
    return result1, result2, result3

def practical_broadcasting_examples():
    """실제 활용 예제"""
    print("\n=== 실제 활용 예제 ===")
    
    # 예제 1: 이미지 데이터 정규화
    print("\n1. 이미지 데이터 정규화 시뮬레이션")
    # 가상의 RGB 이미지 데이터 (높이, 너비, 채널)
    image = np.random.randint(0, 256, (100, 100, 3))
    
    # 각 채널별 평균값
    channel_means = np.mean(image, axis=(0, 1))
    print(f"채널별 평균값: {channel_means}")
    
    # 브로드캐스팅을 사용한 정규화
    normalized_image = image - channel_means
    print(f"정규화 후 채널별 평균값: {np.mean(normalized_image, axis=(0, 1))}")
    
    # 예제 2: 거리 행렬 계산
    print("\n2. 거리 행렬 계산")
    points = np.array([[1, 2], [3, 4], [5, 6], [7, 8]])
    print(f"점들의 좌표:\n{points}")
    
    # 브로드캐스팅을 사용한 유클리드 거리 계산
    # points는 (4, 2), points[:, np.newaxis]는 (4, 1, 2)
    # 결과는 (4, 4, 2)가 되고, 이를 제곱하여 합하면 (4, 4)
    distances = np.sqrt(np.sum((points[:, np.newaxis] - points) ** 2, axis=2))
    print(f"거리 행렬:\n{distances}")
    
    # 예제 3: 온도 데이터 변환
    print("\n3. 온도 데이터 변환 (섭씨 → 화씨)")
    # 일주일간의 시간별 온도 데이터 (7일 x 24시간)
    celsius_temps = np.random.uniform(15, 35, (7, 24))
    
    # 시간대별 보정값 (오전은 차갑게, 오후는 따뜻하게)
    hourly_adjustment = np.sin(np.arange(24) * 2 * np.pi / 24) * 5
    
    # 브로드캐스팅으로 보정값 적용
    adjusted_celsius = celsius_temps + hourly_adjustment
    
    # 화씨로 변환
    fahrenheit_temps = adjusted_celsius * 9/5 + 32
    
    print(f"원본 온도 범위: {celsius_temps.min():.1f}°C ~ {celsius_temps.max():.1f}°C")
    print(f"보정 후 온도 범위: {adjusted_celsius.min():.1f}°C ~ {adjusted_celsius.max():.1f}°C")
    print(f"화씨 온도 범위: {fahrenheit_temps.min():.1f}°F ~ {fahrenheit_temps.max():.1f}°F")
    
    return image, normalized_image, distances, celsius_temps, fahrenheit_temps, hourly_adjustment

def performance_comparison():
    """성능 비교: 브로드캐스팅 vs 반복문"""
    print("\n=== 성능 비교 ===")
    
    # 큰 배열 생성
    large_array = np.random.rand(1000, 1000)
    row_means = np.mean(large_array, axis=1, keepdims=True)
    
    # 방법 1: 브로드캐스팅
    start_time = time.time()
    result_broadcast = large_array - row_means
    broadcast_time = time.time() - start_time
    
    # 방법 2: 반복문
    start_time = time.time()
    result_loop = np.zeros_like(large_array)
    for i in range(large_array.shape[0]):
        result_loop[i] = large_array[i] - row_means[i]
    loop_time = time.time() - start_time
    
    print(f"브로드캐스팅 시간: {broadcast_time:.6f}초")
    print(f"반복문 시간: {loop_time:.6f}초")
    print(f"성능 향상: {loop_time/broadcast_time:.1f}배 빠름")
    
    # 결과가 동일한지 확인
    print(f"결과 동일성: {np.allclose(result_broadcast, result_loop)}")
    
    return broadcast_time, loop_time

def visualize_broadcasting():
    """브로드캐스팅 결과 시각화"""
    print("\n=== 시각화 ===")
    
    # 브로드캐스팅 예제 데이터 생성
    x = np.arange(5)
    y = np.arange(5).reshape(5, 1)
    z = x + y  # 브로드캐스팅 결과
    
    plt.figure(figsize=(15, 10))
    
    # 서브플롯 1: 브로드캐스팅 개념도
    plt.subplot(2, 3, 1)
    plt.imshow(z, cmap='viridis', aspect='auto')
    plt.colorbar()
    plt.title('Broadcasting Result\n(1D + 1D → 2D)')
    
    # 서브플롯 2: 3D 표면 플롯
    plt.subplot(2, 3, 2, projection='3d')
    X, Y = np.meshgrid(x, y.flatten())
    ax = plt.gca()
    ax.plot_surface(X, Y, z, cmap='plasma', alpha=0.8)
    ax.set_title('3D Surface Plot')
    ax.set_xlabel('X')
    ax.set_ylabel('Y')
    ax.set_zlabel('Z')
    
    # 서브플롯 3: 온도 데이터 히트맵
    plt.subplot(2, 3, 3)
    temp_data = np.random.rand(7, 24) * 20 + 15  # 7일 x 24시간 온도
    plt.imshow(temp_data, cmap='coolwarm', aspect='auto')
    plt.colorbar(label='Temperature (°C)')
    plt.title('Weekly Temperature Pattern')
    plt.xlabel('Hour')
    plt.ylabel('Day')
    
    # 서브플롯 4: 거리 행렬 시각화
    plt.subplot(2, 3, 4)
    points = np.random.rand(10, 2) * 10
    distances = np.sqrt(np.sum((points[:, np.newaxis] - points) ** 2, axis=2))
    plt.imshow(distances, cmap='viridis')
    plt.colorbar(label='Distance')
    plt.title('Distance Matrix')
    
    # 서브플롯 5: 브로드캐스팅 벤치마크
    plt.subplot(2, 3, 5)
    array_sizes = [100, 500, 1000, 2000]
    broadcast_times = []
    loop_times = []
    
    for size in array_sizes:
        arr = np.random.rand(size, size)
        means = np.mean(arr, axis=1, keepdims=True)
        
        # 브로드캐스팅 시간 측정
        start = time.time()
        _ = arr - means
        broadcast_times.append(time.time() - start)
        
        # 반복문 시간 측정
        start = time.time()
        result = np.zeros_like(arr)
        for i in range(size):
            result[i] = arr[i] - means[i]
        loop_times.append(time.time() - start)
    
    plt.plot(array_sizes, broadcast_times, 'o-', label='Broadcasting', linewidth=2)
    plt.plot(array_sizes, loop_times, 's-', label='Loop', linewidth=2)
    plt.xlabel('Array Size')
    plt.ylabel('Time (seconds)')
    plt.title('Performance Comparison')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.yscale('log')
    
    # 서브플롯 6: 브로드캐스팅 규칙 도표
    plt.subplot(2, 3, 6)
    plt.text(0.1, 0.8, 'Broadcasting Rules:', fontsize=14, weight='bold')
    plt.text(0.1, 0.7, '1. Arrays are aligned from right', fontsize=10)
    plt.text(0.1, 0.6, '2. Size 1 dimensions are stretched', fontsize=10)
    plt.text(0.1, 0.5, '3. Missing dimensions are added', fontsize=10)
    plt.text(0.1, 0.4, '', fontsize=10)
    plt.text(0.1, 0.3, 'Examples:', fontsize=12, weight='bold')
    plt.text(0.1, 0.2, '(3,4) + (4,) → (3,4)', fontsize=9)
    plt.text(0.1, 0.1, '(3,1) + (1,4) → (3,4)', fontsize=9)
    plt.text(0.1, 0.0, '(3,4,5) + (4,1) → (3,4,5)', fontsize=9)
    plt.xlim(0, 1)
    plt.ylim(0, 1)
    plt.axis('off')
    plt.title('Broadcasting Rules Summary')
    
    plt.tight_layout()
    plt.show()

def main():
    print("=== 문제 1.2: NumPy 브로드캐스팅 이해 및 활용 ===")
    
    # 1. 브로드캐스팅 규칙 시연
    result1, result2, result3 = demonstrate_broadcasting_rules()
    
    # 2. 실제 활용 예제
    image, normalized_image, distances, celsius_temps, fahrenheit_temps, hourly_adjustment = practical_broadcasting_examples()
    
    # 3. 성능 비교
    broadcast_time, loop_time = performance_comparison()
    
    # 4. 시각화
    visualize_broadcasting()
    
    print("\n=== 브로드캐스팅 활용 팁 ===")
    print("1. 메모리 효율성: 불필요한 배열 복사 방지")
    print("2. 성능 향상: 벡터화 연산으로 속도 개선")
    print("3. 코드 간소화: 반복문 없이 간결한 코드")
    print("4. 차원 호환성: reshape, newaxis 활용")

if __name__ == "__main__":
    main()
```

---

### 문제 1.3: Pandas DataFrame 조작 및 데이터 분석

**지시사항:**
1. DataFrame 생성 및 기본 조작
2. 데이터 필터링 및 선택
3. 새로운 열 추가 및 계산
4. 데이터 정렬 및 그룹화

**필요 라이브러리:**
```bash
pip install pandas numpy matplotlib seaborn
```

**실행파일:** `problem_1_3_pandas_dataframe.py`

---

### 문제 1.4: Pandas GroupBy를 활용한 집계 데이터 분석

**지시사항:**
1. 타이타닉 데이터셋 로드 및 탐색
2. 좌석 등급별 생존율 분석
3. 성별-좌석등급별 다중 집계 분석
4. 피벗 테이블 및 시각화

**필요 라이브러리:**
```bash
pip install pandas numpy matplotlib seaborn
```

**실행파일:** `problem_1_4_pandas_groupby.py`

---

## Section 2: 데이터 전처리

### 문제 2.1: 결측값 식별 및 처리 전략 비교

**지시사항:**
1. 결측값 패턴 분석
2. 다양한 대체 전략 비교
3. 그룹별 대체 방법
4. 처리 결과 시각화

**필요 라이브러리:**
```bash
pip install pandas numpy matplotlib seaborn
```

**실행파일:** `problem_2_1_missing_values.py`

---

### 문제 2.2: 이상치 탐지 및 처리

**지시사항:**
1. IQR 방법으로 이상치 탐지
2. Z-score 방법 비교
3. 이상치 처리 전략
4. 시각화를 통한 검증

**필요 라이브러리:**
```bash
pip install pandas numpy matplotlib seaborn scipy
```

**실행파일:** `problem_2_2_outlier_detection.py`

---

### 문제 2.3: 데이터 스케일링 및 정규화

**지시사항:**
1. StandardScaler와 MinMaxScaler 비교
2. 스케일링 전후 분포 비교
3. 머신러닝 성능에 미치는 영향
4. 적절한 스케일링 방법 선택

**필요 라이브러리:**
```bash
pip install pandas numpy matplotlib seaborn scikit-learn
```

**실행파일:** `problem_2_3_data_scaling.py`

---

## Section 3: 데이터 시각화

### 문제 3.1: Matplotlib 서브플롯 활용

**지시사항:**
1. 2x2 서브플롯 구성
2. 다양한 차트 타입 조합
3. 축 레이블 및 제목 설정
4. 색상 및 스타일 커스터마이징

**필요 라이브러리:**
```bash
pip install matplotlib numpy pandas
```

**실행파일:** `problem_3_1_matplotlib_subplots.py`

---

### 문제 3.2: Seaborn을 활용한 통계 시각화

**지시사항:**
1. 상관관계 히트맵 생성
2. 분포 플롯 활용
3. 카테고리별 박스플롯
4. 회귀선이 포함된 산점도

**필요 라이브러리:**
```bash
pip install seaborn matplotlib pandas numpy
```

**실행파일:** `problem_3_2_seaborn_visualization.py`

---

## Section 4: 머신러닝 알고리즘

### 문제 4.1: 선형 회귀 모델 구현 및 평가

**지시사항:**
1. 보스턴 주택 데이터 활용
2. 특성 선택 및 전처리
3. 모델 훈련 및 예측
4. 성능 지표 계산 및 시각화

**필요 라이브러리:**
```bash
pip install scikit-learn pandas numpy matplotlib seaborn
```

**실행파일:** `problem_4_1_linear_regression.py`

---

### 문제 4.2: 로지스틱 회귀를 활용한 분류

**지시사항:**
1. 이진 분류 데이터셋 생성
2. 로지스틱 회귀 모델 훈련
3. 결정 경계 시각화
4. 분류 성능 평가

**필요 라이브러리:**
```bash
pip install scikit-learn pandas numpy matplotlib
```

**실행파일:** `problem_4_2_logistic_regression.py`

---

### 문제 4.3: 의사결정트리 분류 및 해석

**지시사항:**
1. 의사결정트리 모델 구축
2. 트리 구조 시각화
3. 특성 중요도 분석
4. 가지치기 효과 비교

**필요 라이브러리:**
```bash
pip install scikit-learn pandas numpy matplotlib seaborn
```

**실행파일:** `problem_4_3_tree_classification.py`

---

### 문제 4.4: SVM 분류 및 커널 트릭

**지시사항:**
1. 다양한 커널 함수 비교
2. 결정 경계 시각화
3. 하이퍼파라미터 튜닝
4. 비선형 데이터 분류

**필요 라이브러리:**
```bash
pip install scikit-learn pandas numpy matplotlib
```

**실행파일:** `problem_4_4_svm_classification.py`

---

### 문제 4.5: K-Means 클러스터링

**지시사항:**
1. 클러스터 수 결정 (Elbow Method)
2. K-Means 알고리즘 적용
3. 클러스터 결과 시각화
4. 클러스터 특성 분석

**필요 라이브러리:**
```bash
pip install scikit-learn pandas numpy matplotlib seaborn
```

**실행파일:** `problem_4_5_clustering.py`

---

### 문제 4.6: 고객 세분화를 위한 클러스터링

**지시사항:**
1. 고객 데이터 생성 및 전처리
2. 다양한 클러스터링 알고리즘 비교
3. 고객 세그먼트 특성 분석
4. 비즈니스 인사이트 도출

**필요 라이브러리:**
```bash
pip install scikit-learn pandas numpy matplotlib seaborn
```

**실행파일:** `problem_4_6_kmeans_customer_segmentation.py`

---

## Section 5: 딥러닝 및 NLP

### 문제 5.1: 감정 분석 (Sentiment Analysis)

**지시사항:**
1. 텍스트 데이터 전처리
2. TF-IDF 벡터화
3. 감정 분류 모델 훈련
4. 예측 결과 분석

**필요 라이브러리:**
```bash
pip install scikit-learn pandas numpy matplotlib nltk
python -c "import nltk; nltk.download('punkt'); nltk.download('stopwords'); nltk.download('wordnet')"
```

**실행파일:** `problem_5_1_sentiment_analysis.py`

---

### 문제 5.2: 손실 함수 및 역전파 구현

**지시사항:**
1. 간단한 신경망 구조 설계
2. 순전파 및 역전파 수동 구현
3. 경사 하강법 최적화
4. 학습 과정 시각화

**필요 라이브러리:**
```bash
pip install numpy matplotlib
```

**실행파일:** `problem_5_2_loss_backprop.py`

---

### 문제 5.3: 딥러닝을 활용한 감정 분석

**지시사항:**
1. LSTM 네트워크 구성
2. 텍스트 시퀀스 처리
3. 모델 훈련 및 검증
4. 성능 비교 분석

**필요 라이브러리:**
```bash
pip install tensorflow scikit-learn pandas numpy matplotlib nltk
python -c "import nltk; nltk.download('punkt'); nltk.download('stopwords')"
```

**실행파일:** `problem_5_3_deep_sentiment_analysis.py`

---

## Section 6: 모델 평가

### 문제 6.1: CNN을 활용한 CIFAR-10 이미지 분류

**지시사항:**
1. CIFAR-10 데이터셋 로드
2. CNN 모델 구조 설계
3. 데이터 증강 적용
4. 모델 평가 및 시각화

**필요 라이브러리:**
```bash
pip install tensorflow numpy matplotlib
```

**실행파일:** `problem_6_1_cnn_cifar10.py`

---

### 문제 6.2: 혼동 행렬 기반 평가 지표

**지시사항:**
1. 혼동 행렬 계산 및 시각화
2. 정밀도, 재현율, F1-score 계산
3. ROC 곡선 및 AUC 분석
4. 다중 클래스 평가 지표

**필요 라이브러리:**
```bash
pip install scikit-learn pandas numpy matplotlib seaborn
```

**실행파일:** `problem_6_2_confusion_matrix.py`

---

### 문제 6.3: GridSearchCV 하이퍼파라미터 최적화

**지시사항:**
1. 다양한 모델 하이퍼파라미터 탐색
2. 교차 검증과 결합
3. 최적화 결과 시각화
4. Pipeline을 통한 통합 최적화

**필요 라이브러리:**
```bash
pip install scikit-learn pandas numpy matplotlib seaborn
```

**실행파일:** `problem_6_3_gridsearch.py`

---

## 실행 방법

### 전체 라이브러리 한번에 설치
```bash
pip install numpy pandas matplotlib seaborn scikit-learn tensorflow nltk scipy
python -c "import nltk; nltk.download('punkt'); nltk.download('stopwords'); nltk.download('wordnet')"
```

### 개별 문제 실행
```bash
# 예시: 첫 번째 문제 실행
python problem_1_1_numpy_operations.py

# 모든 문제 실행 (순차적으로)
for file in problem_*.py; do python "$file"; done
```

### 주의사항
1. 한글 폰트 관련 경고는 무시하고 진행하세요
2. 일부 시각화에서 폰트가 깨질 수 있지만 실행에는 문제없습니다
3. GPU 가속을 위해서는 tensorflow-gpu를 설치하세요
4. 메모리 부족 시 배치 크기를 줄여서 실행하세요

---

## 완성 확인

✅ **총 21개 문제 모두 구현 완료**
- Section 1: 4개 문제 (기초 데이터 분석)
- Section 2: 3개 문제 (데이터 전처리)  
- Section 3: 2개 문제 (데이터 시각화)
- Section 4: 6개 문제 (머신러닝)
- Section 5: 3개 문제 (딥러닝/NLP)
- Section 6: 3개 문제 (모델 평가)

✅ **모든 파일 실행 가능한 상태로 검증 완료**
✅ **필요 라이브러리 목록 제공**
✅ **상세한 문제 설명 및 지시사항 포함**