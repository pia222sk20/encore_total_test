# LLM 실습 문제 - 개선판

> **지시사항 원칙**: 정확하고 간결하게 · 코드는 지시사항 충실 · 실제 데이터 사용

---

## 📚 목차

### Chapter 1: 텍스트 데이터의 표현
- [1.1 텍스트 전처리](#11-텍스트-전처리)
- [1.2 TF-IDF 벡터화](#12-tfidf-벡터화)
- [1.3 단어 임베딩](#13-단어-임베딩)

### Chapter 2: 자연어 딥러닝
- [2.1 LSTM 감정 분석](#21-lstm-감정-분석)
- [2.2 BERT 감정 분석](#22-bert-감정-분석)

### Chapter 3: 초거대 언어 모델
- [3.1 GPT 텍스트 완성](#31-gpt-텍스트-완성)
- [3.2 생성 파라미터 제어](#32-생성-파라미터-제어)
- [3.3 마케팅 카피 생성](#33-마케팅-카피-생성)

### Chapter 4: 고급 프롬프트 엔지니어링
- [4.1 Few-Shot 학습](#41-few-shot-학습)
- [4.2 RAG 시스템](#42-rag-retrieval-augmented-generation)
- [4.3 Chain-of-Thought](#43-chain-of-thought)

### Chapter 5: 파인튜닝
- [5.1 LoRA 파인튜닝](#51-lora-파인튜닝)
- [5.2 보상 모델 훈련](#52-보상-모델-훈련)

### Chapter 6: 멀티모달 AI
- [6.1 이미지 캡셔닝](#61-이미지-캡셔닝)
- [6.2 Stable Diffusion](#62-stable-diffusion)

---

## Chapter 1: 텍스트 데이터의 표현

### 1.1 텍스트 전처리

**목표**: 원시 텍스트를 기계학습에 적합한 형태로 정제하기

원시 텍스트를 자연어 처리 모델이 이해할 수 있도록 정제하는 과정입니다. 텍스트 전처리는 NLP의 가장 기초적이면서도 중요한 단계로, 데이터 품질이 모델 성능에 직접 영향을 미칩니다. 이 문제에서는 소문자 변환, 토큰화, 구두점 제거, 불용어 제거 등의 기본 전처리 기법을 단계별로 적용합니다.

**지시사항:**

1. **NLTK 라이브러리 로드 및 데이터 다운로드**
   - `nltk.download('punkt')`: 토크나이저 데이터
   - `nltk.download('stopwords')`: 불용어 데이터

2. **3개 샘플 문장에 전처리 적용**
   - 각 문장을 소문자로 변환
   - `word_tokenize()` 로 단어/구두점 분리
   - 구두점 제거 (`isalpha()` 사용)
   - 영어 불용어 제거

3. **각 단계별 결과 출력**
   - 원본 문장 → 토큰화 → 정제 과정을 순차적으로 표시
   - 제거된 토큰 명시

4. **통계 정보 계산**
   - 원본 단어 수, 최종 단어 수, 압축률
   - 고유 단어 개수

**필수 라이브러리:**
```bash
pip install nltk
```

**평가 기준:**
- ✓ 3개 문장 모두 전처리
- ✓ 각 단계별 명확한 출력
- ✓ 불용어 제거 정확성
- ✓ 통계 정보 계산

**파일명:** `llm_1_1_text_preprocessing.py`

---

### 1.2 TF-IDF 벡터화

**목표**: 텍스트를 숫자 벡터로 변환하여 기계학습 모델에 입력 가능하게 하기

TF-IDF(Term Frequency-Inverse Document Frequency)는 문서 내 각 단어의 중요도를 수치화하는 방법입니다. 자주 나타나지만 의미가 없는 단어는 낮은 가중치를, 드물지만 정보를 담은 단어는 높은 가중치를 부여합니다.

**지시사항:**

1. **문서 수집**
   - 5개 이상의 짧은 문서(문장) 준비
   - 각 문서는 2-3개 문장 길이

2. **TfidfVectorizer 생성 및 학습**
   - `sklearn.feature_extraction.text.TfidfVectorizer` 사용
   - `max_features=50` 으로 상위 50개 특성만 사용
   - 소문자 변환, 영어 불용어 제거 설정

3. **TF-IDF 행렬 생성**
   - 문서-단어 TF-IDF 행렬 생성
   - 행렬 형태 출력 (희소 행렬)

4. **결과 분석**
   - 각 문서별 상위 5개 중요 단어 추출
   - 단어별 TF-IDF 값 계산 및 비교
   - 특성 이름(단어) 확인

5. **시각화**
   - 문서별 중요 단어 TF-IDF 점수를 막대 그래프로 표현
   - 서로 다른 문서의 특징 비교

**필수 라이브러리:**
```bash
pip install scikit-learn matplotlib
```

**평가 기준:**
- ✓ 5개 이상 문서 사용
- ✓ TF-IDF 행렬 정확히 생성
- ✓ 각 문서별 상위 단어 추출
- ✓ 시각화 포함

**파일명:** `llm_1_2_tfidf_vectorization.py`

---

### 1.3 단어 임베딩

**목표**: 단어를 의미 있는 벡터로 표현하여 단어 간 의미 관계 포착하기

Word2Vec, GloVe, FastText 등의 임베딩 방식은 단어를 고정 크기의 벡터로 변환하여 의미론적 유사성을 수치로 표현합니다. 임베딩된 벡터 공간에서 유사한 의미의 단어들은 가까운 위치에 분포합니다.

**지시사항:**

1. **Gensim Word2Vec 모델 학습**
   - 사전 학습된 모델 사용 또는 간단한 문장 셋으로 학습
   - 임베딩 차원: 100차원

2. **단어 벡터 탐색**
   - 특정 단어의 벡터 표시
   - 벡터 크기 및 통계 정보 (평균, 표준편차)

3. **유사 단어 찾기**
   - `most_similar()` 메서드로 상위 5개 유사 단어 추출
   - 코사인 유사도 값 표시

4. **단어 유추**
   - 예: "king" - "man" + "woman" ≈ "queen"
   - `most_similar(positive=['king', 'woman'], negative=['man'])`

5. **시각화**
   - 벡터 간 유사도 행렬 히트맵
   - 유사 단어들의 코사인 유사도 분포

**필수 라이브러리:**
```bash
pip install gensim scikit-learn matplotlib seaborn numpy
```

**평가 기준:**
- ✓ Word2Vec 모델 정상 로드/학습
- ✓ 유사 단어 검색 정확성
- ✓ 단어 유추 작동
- ✓ 시각화 포함

**파일명:** `llm_1_3_word_embeddings.py`

---

## Chapter 2: 자연어 딥러닝

### 2.1 LSTM 감정 분석

**목표**: LSTM 신경망을 이용한 텍스트 감정 분류 모델 구축

LSTM(Long Short-Term Memory)은 순차 데이터의 장기 의존성을 학습할 수 있는 RNN 변형입니다. 텍스트의 맥락을 이해하여 감정(긍정/부정)을 분류하는 데 효과적입니다.

**지시사항:**

1. **IMDB 영화 리뷰 데이터셋 로드**
   - `tensorflow.keras.datasets.imdb` 사용
   - 훈련 샘플 5,000개, 테스트 샘플 1,000개로 제한

2. **데이터 전처리**
   - 정수 인덱스를 단어로 복원
   - 시퀀스 길이 정규화 (최대 200단어로 패딩)
   - 훈련/검증 데이터 분할

3. **LSTM 모델 구성**
   - 임베딩 레이어: 128차원
   - LSTM 레이어: 64개 유닛
   - Dense 레이어: 16개 유닛 (ReLU)
   - 출력 레이어: 1개 유닛 (Sigmoid)

4. **모델 컴파일 및 훈련**
   - 옵티마이저: Adam
   - 손실 함수: binary_crossentropy
   - 메트릭: accuracy
   - 에포크: 5, 배치 크기: 32

5. **모델 평가**
   - 테스트 데이터셋 평가
   - 정확도, 손실 값 출력
   - 훈련/검증 곡선 시각화

6. **새 리뷰 분류**
   - 샘플 리뷰 3개에 대해 긍정/부정 예측
   - 신뢰도(확률) 표시

**필수 라이브러리:**
```bash
pip install tensorflow matplotlib numpy
```

**평가 기준:**
- ✓ LSTM 모델 정상 구성 및 훈련
- ✓ 테스트 정확도 75% 이상
- ✓ 훈련/검증 곡선 시각화
- ✓ 새 리뷰 분류 작동

**파일명:** `llm_2_1_lstm_sentiment.py`

---

### 2.2 BERT 감정 분석

**목표**: 사전 학습된 BERT 모델을 이용한 고정확도 감정 분석

BERT(Bidirectional Encoder Representations from Transformers)는 양방향으로 문맥을 학습하여 뛰어난 자연어 이해 성능을 제공합니다. 파인튜닝 없이도 우수한 성능을 달성할 수 있습니다.

**지시사항:**

1. **Hugging Face 트랜스포머 라이브러리 사용**
   - `transformers.pipeline` 으로 감정 분석 파이프라인 로드
   - 사전학습 모델: distilbert-base-uncased-finetuned-sst-2-english

2. **샘플 리뷰 수집**
   - 긍정 리뷰 3개
   - 부정 리뷰 3개
   - 중립 리뷰 2개 (선택)

3. **각 리뷰 분류**
   - 감정 레이블 (POSITIVE/NEGATIVE)
   - 신뢰도 점수 (0-1 범위)
   - 분류 결과 비교

4. **모델 비교**
   - LSTM과 BERT 성능 비교
   - 테이블 형식으로 정확도, 처리 속도, 신뢰도 비교

5. **시각화**
   - 각 리뷰의 감정 분포 막대 그래프
   - 모델별 성능 비교 그래프

**필수 라이브러리:**
```bash
pip install transformers torch scikit-learn matplotlib
```

**평가 기준:**
- ✓ BERT 모델 정상 로드
- ✓ 6개 이상 리뷰 분류
- ✓ 신뢰도 점수 계산
- ✓ LSTM과 비교 분석

**파일명:** `llm_2_2_bert_sentiment.py`

---

## Chapter 3: 초거대 언어 모델

### 3.1 GPT 텍스트 완성

**목표**: GPT API를 사용하여 자동으로 텍스트 생성하기

GPT(Generative Pre-trained Transformer) 모델은 주어진 프롬프트를 기반으로 자연스럽고 창의적인 텍스트를 생성합니다. 이 문제에서는 API 호출 방식을 학습합니다.

**지시사항:**

1. **OpenAI API 설정** (또는 대체 모델)
   - API 키 환경 변수 설정
   - 또는 로컬 모델 사용 (Ollama, LLaMA 등)

2. **프롬프트 작성**
   - 프롬프트 1: 제품 설명 완성
   - 프롬프트 2: 이야기 시작 완성
   - 프롬프트 3: 코드 주석 완성

3. **생성 실행**
   - 각 프롬프트에 대해 텍스트 생성
   - 생성 시간 측정

4. **결과 분석**
   - 생성된 텍스트의 길이, 문법 정확성
   - 다양성 평가

5. **결과 저장**
   - 생성된 텍스트를 파일에 저장
   - 프롬프트와 결과를 쌍으로 표시

**필수 라이브러리:**
```bash
pip install openai python-dotenv
# 또는
pip install ollama
```

**평가 기준:**
- ✓ API 정상 연동
- ✓ 3개 이상 프롬프트 생성
- ✓ 생성 결과 저장
- ✓ 다양한 프롬프트 유형 시도

**파일명:** `llm_3_1_gpt_text_completion.py`

---

### 3.2 생성 파라미터 제어

**목표**: 온도, 상위-P 샘플링 등 파라미터 조절로 생성 방식 제어하기

LLM의 생성 다양성과 일관성은 온도(temperature), 상위-K, 상위-P 등의 파라미터로 조절할 수 있습니다. 이 문제에서는 각 파라미터가 생성 결과에 미치는 영향을 실험합니다.

**지시사항:**

1. **동일 프롬프트로 다양한 파라미터 테스트**
   - 프롬프트: "The future of AI is"

2. **온도(Temperature) 변화**
   - 온도 0.1 (일관성 높음)
   - 온도 0.5 (균형)
   - 온도 1.0 (표준)
   - 온도 1.5 (창의성 높음)

3. **Top-P (Nucleus Sampling) 변화**
   - P=0.5, 0.7, 0.9, 0.95

4. **생성 결과 수집 및 비교**
   - 각 설정별 생성된 텍스트 저장
   - 생성 다양성 평가 (어휘 다양성, 문법 정확성)

5. **시각화**
   - 온도별 텍스트 길이 비교
   - 설정별 키워드 분포
   - 다양성 지표 시각화

**필수 라이브러리:**
```bash
pip install openai matplotlib numpy collections
```

**평가 기준:**
- ✓ 4개 온도값으로 텍스트 생성
- ✓ 3개 이상 P값 테스트
- ✓ 파라미터별 차이 명확히 보임
- ✓ 시각화 포함

**파일명:** `llm_3_2_generation_parameters.py`

---

### 3.3 마케팅 카피 생성

**목표**: 프롬프트 엔지니어링으로 실용적인 마케팅 텍스트 자동 생성하기

효과적인 프롬프트 작성을 통해 LLM이 특정 스타일과 목표에 맞는 마케팅 카피를 생성하도록 유도합니다. 제약 조건을 명시하고 예시를 제공하는 기법을 배웁니다.

**지시사항:**

1. **제품 정보 정의**
   - 제품명, 특징, 타겟 고객 정의
   - 3개 서로 다른 제품 선택

2. **프롬프트 템플릿 작성**
   - 역할 정의: "You are a marketing expert"
   - 제약 조건: "Keep it under 100 words"
   - 예시 제공 (Few-shot)

3. **마케팅 텍스트 생성**
   - 각 제품별로 3가지 톤(formal, casual, urgent)으로 생성
   - 총 9개 카피 생성

4. **품질 평가**
   - 생성된 텍스트 길이 확인
   - 키워드 포함 여부 검증
   - 문법 및 가독성 평가

5. **결과 정렬**
   - 제품별, 톤별로 카피 정렬
   - 가장 효과적인 카피 표시 (팀 토론)

**필수 라이브러리:**
```bash
pip install openai pandas
```

**평가 기준:**
- ✓ 3개 제품 마케팅 카피 생성
- ✓ 3가지 톤 적용
- ✓ 제약 조건 준수 (100단어 이내)
- ✓ 평가 기준 명확

**파일명:** `llm_3_3_marketing_copy_generator.py`

---

## Chapter 4: 고급 프롬프트 엔지니어링

### 4.1 Few-Shot 학습

**목표**: 예시를 제공하여 LLM이 패턴을 인식하고 새로운 작업 수행하기

Few-shot 학습은 모델을 추가로 훈련하지 않고도 몇 가지 예시만으로 새로운 작업을 수행하도록 지도합니다.

**지시사항:**

1. **감정 분류 Few-Shot 예시**
   - 3개 훈련 예시 제공 (긍정, 부정, 중립)
   - 각 예시: (문장, 라벨)

2. **테스트 문장 분류**
   - 예시를 포함한 프롬프트 작성
   - 5개 테스트 문장 분류

3. **번역 Few-Shot 예시**
   - 영어 → 한국어 번역 예시 3개
   - 5개 새 문장 번역

4. **정보 추출 Few-Shot**
   - 문장에서 인명/장소/조직 추출
   - 3개 훈련 예시
   - 5개 테스트 문장 처리

5. **정확도 평가**
   - 각 작업별 정확도 계산
   - 오류 분석

**필수 라이브러리:**
```bash
pip install openai
```

**평가 기준:**
- ✓ 3개 다양한 작업 시도
- ✓ 각 작업별 3개 이상 훈련 예시
- ✓ 5개 이상 테스트 샘플
- ✓ 정확도 계산

**파일명:** `llm_4_1_few_shot_learning.py`

---

### 4.2 RAG (Retrieval Augmented Generation)

**목표**: 외부 지식 베이스를 검색하여 답변 생성하기

RAG는 대규모 문서 컬렉션에서 관련 정보를 검색한 후, 이를 바탕으로 LLM이 답변을 생성하는 방식입니다. 할루시네이션을 줄이고 최신 정보 활용을 가능하게 합니다.

**지시사항:**

1. **문서 컬렉션 준비**
   - 5-10개의 짧은 문서 (회사 정책, FAQ, 기술 문서 등)
   - 각 문서는 200-500자 길이

2. **벡터 데이터베이스 구축**
   - LangChain 또는 Chroma 사용
   - 문서를 임베딩으로 변환
   - 벡터 저장소에 저장

3. **검색 쿼리 실행**
   - 5개 쿼리 준비
   - 관련 문서 상위 3개 검색

4. **답변 생성**
   - 검색된 문서를 컨텍스트로 포함
   - LLM에 질문 전달
   - 생성된 답변 출력

5. **평가**
   - 생성된 답변이 컨텍스트 기반인지 확인
   - 할루시네이션 없음 검증

**필수 라이브러리:**
```bash
pip install langchain openai chromadb
```

**평가 기준:**
- ✓ 5-10개 문서로 벡터DB 구축
- ✓ 5개 쿼리 검색 및 답변 생성
- ✓ 컨텍스트 기반 답변 확인
- ✓ 할루시네이션 최소화

**파일명:** `llm_4_2_langchain_rag.py`

---

### 4.3 Chain-of-Thought

**목표**: 단계별 추론 과정을 명시하여 복잡한 문제 해결하기

Chain-of-Thought 프롬프팅은 LLM이 최종 답변 전에 중간 추론 단계를 명시하도록 유도하여, 복잡한 문제에서 정확도를 향상시킵니다.

**지시사항:**

1. **수학 문제 해결**
   - 3개 다단계 수학 문제 준비
   - CoT 프롬프트: "먼저 단계적으로 생각해보세요"
   - 직접 답변과 비교

2. **논리 추론**
   - 3개 논리 퍼즐 또는 추론 문제
   - 단계적 사고 프롬프트 적용
   - 정답률 비교

3. **복잡한 질문**
   - 3개 다각도 분석이 필요한 질문
   - CoT와 일반 프롬프트 성능 비교

4. **결과 분석**
   - 각 방식별 정확도
   - 처리 시간 비교
   - 생성 토큰 수 비교

5. **시각화**
   - 방식별 정확도 비교 막대 그래프
   - 추론 단계 시각화

**필수 라이브러리:**
```bash
pip install openai matplotlib
```

**평가 기준:**
- ✓ 9개 이상 문제 (3종류 × 3개)
- ✓ CoT와 직접 답변 비교
- ✓ 정확도 계산
- ✓ 시각화 포함

**파일명:** `llm_4_3_chain_of_thought.py`

---

## Chapter 5: 파인튜닝

### 5.1 LoRA 파인튜닝

**목표**: LoRA(Low-Rank Adaptation)로 대규모 모델을 효율적으로 파인튜닝하기

LoRA는 전체 모델을 훈련하지 않고 작은 저랭크 행렬만 추가하여 모델을 특정 작업에 맞게 적응시킵니다. 메모리 효율적이고 빠른 훈련이 가능합니다.

**지시사항:**

1. **기본 모델 로드**
   - Hugging Face에서 사전 학습 모델 다운로드 (distilbert 또는 유사)
   - 모델 크기 확인

2. **LoRA 어댑터 구성**
   - `peft` 라이브러리 사용
   - LoRA 랭크: 8, 알파: 32

3. **파인튜닝 데이터 준비**
   - 특정 도메인 데이터 100개 샘플
   - 훈련/검증 분할

4. **파인튜닝 실행**
   - 에포크: 3
   - 배치 크기: 8
   - 학습률: 2e-4

5. **모델 평가**
   - 파인튜닝 전/후 성능 비교
   - 검증 손실 곡선

6. **메모리 사용량 비교**
   - LoRA vs 전체 파인튜닝 메모리 비교

**필수 라이브러리:**
```bash
pip install peft transformers datasets torch
```

**평가 기준:**
- ✓ LoRA 어댑터 정상 구성
- ✓ 100개 샘플로 파인튜닝 완료
- ✓ 전/후 성능 비교
- ✓ 메모리 효율성 확인

**파일명:** `llm_5_1_lora_finetuning.py`

---

### 5.2 보상 모델 훈련

**목표**: RLHF(Reinforcement Learning from Human Feedback)의 보상 모델 구축하기

보상 모델은 두 개의 답변을 비교하여 어느 것이 더 좋은지 판단합니다. RLHF의 첫 단계로 LLM을 인간의 선호도에 맞게 정렬시키는 데 사용됩니다.

**지시사항:**

1. **비교 데이터 수집**
   - 질문과 쌍의 답변들 준비
   - 각 쌍: (질문, 답변A, 답변B, 선호도)
   - 최소 50개 쌍

2. **데이터 전처리**
   - 답변 인코딩
   - 라벨 설정 (선호도)

3. **보상 모델 구축**
   - 기본 모델 로드
   - 분류 헤드 추가 (답변A vs B 선택)

4. **모델 훈련**
   - 이진 분류 손실 함수
   - 에포크: 3, 배치 크기: 8

5. **모델 평가**
   - 검증 정확도
   - 혼동행렬

6. **시각화**
   - 훈련 손실 곡선
   - 검증 정확도 곡선

**필수 라이브러리:**
```bash
pip install transformers datasets torch scikit-learn matplotlib
```

**평가 기준:**
- ✓ 50개 이상 쌍 데이터
- ✓ 모델 훈련 완료
- ✓ 검증 정확도 70% 이상
- ✓ 곡선 시각화

**파일명:** `llm_5_2_rlhf_reward_model.py`

---

## Chapter 6: 멀티모달 AI

### 6.1 이미지 캡셔닝

**목표**: 이미지로부터 자동으로 설명 텍스트 생성하기

이미지 캡셔닝은 컴퓨터 비전과 자연어 생성을 결합하는 멀티모달 작업입니다. 이미지의 내용을 분석하여 자연스러운 문장으로 설명합니다.

**지시사항:**

1. **모델 로드**
   - `transformers.VisionEncoderDecoderModel` 또는 `BLIP` 모델
   - 사전 학습 가중치 다운로드

2. **테스트 이미지 준비**
   - 3개 이상의 이미지 URL 또는 로컬 파일
   - 다양한 장면 (풍경, 동물, 사람 등)

3. **이미지 전처리**
   - 이미지 로드
   - 모델 입력 형식으로 정규화

4. **캡션 생성**
   - 각 이미지별 캡션 생성
   - 빔 서치(beam search) 파라미터 조정

5. **결과 시각화**
   - 이미지와 캡션을 나란히 표시

6. **품질 평가**
   - 생성된 캡션의 문법 정확성
   - 이미지 내용 일치도 평가

**필수 라이브러리:**
```bash
pip install transformers pillow torch matplotlib requests
```

**평가 기준:**
- ✓ 3개 이상 이미지 처리
- ✓ 캡션 정상 생성
- ✓ 이미지-캡션 시각화
- ✓ 품질 평가 포함

**파일명:** `llm_6_1_image_captioning.py`

---

### 6.2 Stable Diffusion

**목표**: 텍스트 설명으로부터 이미지 생성하기

Stable Diffusion은 텍스트 프롬프트를 입력받아 고품질 이미지를 생성합니다. 창의적인 콘텐츠 생성, 시각화, 디자인 등에 활용됩니다.

**지시사항:**

1. **Stable Diffusion 모델 로드**
   - Hugging Face의 사전 학습 모델 사용
   - 또는 로컬 설치된 모델

2. **프롬프트 작성**
   - 5개 다양한 이미지 생성 프롬프트
   - 예: "A serene mountain landscape at sunset", "A futuristic robot" 등

3. **이미지 생성**
   - 각 프롬프트별 이미지 생성
   - 생성 단계: 50

4. **프롬프트 최적화**
   - 같은 주제로 더 자세한 프롬프트 시도
   - 스타일 키워드 추가 ("oil painting", "photorealistic" 등)
   - 품질 비교

5. **이미지 저장**
   - 생성된 이미지를 PNG로 저장
   - 프롬프트와 함께 메타데이터 기록

6. **시각화**
   - 생성된 이미지 그리드 표시
   - 프롬프트별 결과 비교

**필수 라이브러리:**
```bash
pip install diffusers transformers torch pillow
```

**평가 기준:**
- ✓ 5개 이상 프롬프트로 이미지 생성
- ✓ 이미지 정상 생성 및 저장
- ✓ 프롬프트 최적화 시도
- ✓ 결과 시각화

**파일명:** `llm_6_2_stable_diffusion.py`

---

## 📊 전체 문제 요약

| 챕터 | 주제 | 문제 수 | 난이도 |
|------|------|--------|--------|
| 1 | 텍스트 표현 | 3 | ⭐⭐ |
| 2 | NLP 딥러닝 | 2 | ⭐⭐⭐ |
| 3 | 초거대 LLM | 3 | ⭐⭐⭐ |
| 4 | 프롬프트 엔지니어링 | 3 | ⭐⭐⭐⭐ |
| 5 | 파인튜닝 | 2 | ⭐⭐⭐⭐ |
| 6 | 멀티모달 AI | 2 | ⭐⭐⭐ |
| **합계** | **LLM 실습** | **18개** | **-** |

---

## 📦 필수 라이브러리 통합 설치

```bash
# 기본 라이브러리
pip install numpy pandas matplotlib seaborn scikit-learn

# NLP 라이브러리
pip install nltk gensim scikit-learn

# 딥러닝
pip install tensorflow torch transformers

# LLM API
pip install openai langchain

# 고급 기능
pip install peft datasets chromadb diffusers pillow

# 모든 것을 한 번에
pip install numpy pandas matplotlib seaborn scikit-learn nltk gensim tensorflow torch transformers openai langchain peft datasets chromadb diffusers pillow
```

---

## 💡 학습 순서 권장안

### **1주차: 기초 (난이도 ⭐⭐)**
- 1.1 텍스트 전처리
- 1.2 TF-IDF 벡터화
- 1.3 단어 임베딩

### **2주차: NLP 딥러닝 (난이도 ⭐⭐⭐)**
- 2.1 LSTM 감정 분석
- 2.2 BERT 감정 분석

### **3주차: LLM 활용 (난이도 ⭐⭐⭐)**
- 3.1 GPT 텍스트 완성
- 3.2 생성 파라미터 제어
- 3.3 마케팅 카피 생성

### **4주차: 고급 기법 (난이도 ⭐⭐⭐⭐)**
- 4.1 Few-Shot 학습
- 4.2 RAG 시스템
- 4.3 Chain-of-Thought

### **5주차: 파인튜닝 & 멀티모달 (난이도 ⭐⭐⭐⭐)**
- 5.1 LoRA 파인튜닝
- 5.2 보상 모델 훈련
- 6.1 이미지 캡셔닝
- 6.2 Stable Diffusion

---

## 🎯 평가 기준

### **코드 품질 (40%)**
- 지시사항 준수 정도
- 코드 가독성 및 구조
- 에러 처리

### **기능 완성도 (40%)**
- 모든 단계 구현
- 예상 출력 달성
- 시각화 포함

### **창의성 (20%)**
- 추가 실험 시도
- 파라미터 개선
- 결과 분석 심화

---

## ❓ FAQ

**Q: API 키가 없는데 어떻게 하나요?**
A: 로컬 모델(Ollama, LLaMA) 또는 오픈소스 모델 사용 가능합니다.

**Q: GPU가 없어도 되나요?**
A: CPU로도 작동 가능하지만 훨씬 느립니다. Google Colab 무료 GPU 사용 권장.

**Q: 샘플 코드는 어디서 확인하나요?**
A: `llm_*.py` 파일들이 각 문제의 예시 솔루션입니다.

---

**마지막 업데이트**: 2025-01-16  
**총 문제**: 18개  
**총 학습 시간**: 약 40-50시간
